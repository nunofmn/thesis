\chapter{Implementation}
\label{chapter:implementation}

This chapter addresses the main decisions adopted regarding the implementation of the IDChain, vanilla an CA-based systems. Therefore, the following sections cover the technologies that were used in the development process and the implementation details of each component.

\section{Adopted Technologies}

In this section we will present the chosen technologies to implement the proposed work, for each component of the architecture.

\subsection{DHT}

In a first instance, the chosen library to implement the DHT node was \textit{TomP2P}\footnote{http://tomp2p.net/} a implementation of Kademlia in Java.
The use of TomP2P was already decided before-hand, since the Global Registry component in the reThink project, was already partially implemented using it.
This restricted the implementation options from the get-go, since it wasn't possible to compare different \ac{DHT} implementations and check which one could be more easily extended.

We tried to modify the TomP2P source code, and implement TLS connection supports.
This endeavor didn't succeeded, mainly since the TomP2P code is tightly coupled to TCP and UDP connections.
Since TomP2P uses \textit{Netty}\footnote{https://netty.io/}, a Java NIO client-server \ac{NIO} framework, we tried to to change Netty instance calls to TLS, a try which revealed infeasible.

Therefore we decided to implement the mechanisms using another DHT system.
Several DHT implementations exist in different languages, but was necessary to pin down an implementation that had a modular architecture and could be easily extended.

The implementation that revealed to be the most modular was the one of \textit{Kad}\footnote{https://kadtools.github.io} library, for \textit{Node.js}\footnote{https://nodejs.org/} and based on Kademlia.
This implementation allows to easily extend the base DHT with custom transports, middleware, storage layers and message processors, which enabled us to build a custom transport with TLS mutual-authentication and custom verification rules.

The same DHT client was used for the three different mechanisms: vanilla, CA-based and IDChain.
Is possible to switch between the three different mechanisms by declaring in the configuration file which one we want to use.

\subsection{Blockchain}

The blockchain that we used is Ethereum.
There are a number of other blockchains currently available that enable developers to build applications on top of it using smart contracts, like Hyperledger Fabric\cite{cachin2016architecture} or R3 Corda\cite{mikehearn2016}, but these implementations have more specific use-cases, enterprise and finances respectively.

A quick analysis between these three platforms show significant architectural differences, in such a way that we can even consider an higher-level classification for these three platforms, since not all of them show the main characteristics of a blockchain (taking in consideration the Bitcoin reference paper).
A broader definition that encapsulates this three platforms is \ac{DLT}.

The Hyperledger Fabric platform has a modular approach to blockchains. It's a private blockchain system  and is permissioned, i.e doesn't allow unknown entities to participate in the system.
To participate in the system the members of a Hyperledger Fabric system, must enroll through a \ac{MSP}.
This allows different architectural approaches in the system, because is not strictly necessary to have a \ac{POW} mechanism, like in Ethereum or Bitcoin (which may be considered open networks), and is possible to use different consensus mechanisms in the network.
Also, there isn't any built-in currency like in Bitcoin or Ethereum.

The R3 Corda system is considered a \ac{DLT} for financial institutions.
Is also permissioned and private, and uses a concept of notary nodes to validate uniqueness of transactions. Like Fabric, also allows a more fine-grained control of the consensus mechanism.
Data is shared on a need-to-know basis, there is no global broadcast of all the transactions in the system.

Finally, the Ethereum platform is the more generic blockchain platform of the ones referenced.
Is permission-less, and can be public or private.
All the participants have to achieve consensus over all the transactions of the system, using the \ac{POW} consensus and leveraging the built-in currency (ether).

Our choice was Ethereum due to a number of reasons:

\begin{itemize}
	\item Permissionless - even thought we want to build our mechanism around a federated/enterprise model, this proof of concept may be easily adapted to be used as a global system.
  Since the Ethereum network is public, and we could also deploy private instances, it is the right fit.
	\item Developer ecosystem - right now, Ethereum has the biggest developer community, with a increasing number of development tools to aid the development and deploy process of smart contracts.
\end{itemize}


Even thought the Ethereum network is currently the system with the better developer ecosystem, there are still several shortcomings when developing against it.
In Section~\ref{implementation:idchain} we detail some of the difficulties and shortcomings of the Ethereum smart contracts we encountered during development.

\subsection{IDChain API}

\subsubsection{Application Server}

The IDChain API was built using the Node.js Javascript runtimes, and the following frameworks and libraries:

\begin{itemize}
  \item \textit{Hapi}\footnote{https://hapijs.com/} - web framework for building web applications, RESTful APIs and services;
  \item \textit{web3.js}\footnote{https://github.com/ethereum/web3.js/} - the Ethereum compatible Javascript API;
  \item \textit{Sequelize}\footnote{https://sequelizejs.com} - a \ac{ORM} for Node.js which support several SQL dialects.
\end{itemize}

The decision of using Node.js to develop the HTTP API is mainly related with the web3.js library.
At the time of development was the most mature library to interface with the Ethereum client.
The Ruby, Java and .Net implementations were still in early stages of development.

% verificar isto
The Hapi framework was chosen because allows to build APIs encapsulating APIs endpoints around a plugin system. For example, is possible to create a plugin that encapsulates all the endpoints that are related with the certificates domain.
This allow to compose the API using tiny modules that contain the business logic of each domain in the application, which later could be easily decoupled and deploy separately.
Also Hapi has already a couple of modules built-in for dealing with input and response validation, error handling, session caching, logging, etc.

We decided to use an \ac{ORM} to interact with the database due to the following reasons:

\begin{itemize}
  \item Allows easier implementation of the entities in the API;
  \item Leads to a huge reduction in code, since eliminates the need for repetitive SQL queries;
  \item Easier navigation of entities relationships;
  \item Transaction management and isolation;
  \item Independent of the SQL database or dialect used, allowing to use any SQL database or dialect.
\end{itemize}

We decided to use the Sequelize ORM, since is the most mature and fully-fledge SQL ORM for Node.js.

\subsubsection{Database}

The database we decide used with the IDChain API was \textit{PostgreSQL}\footnote{https://www.postgresql.org/}.
The decision to use SQL comes from the necessity of predefining a schema and normalize the processed data from the blockchain.
This allowed us to easily establish relationships between the entities in the system (transactions, certificates, etc), which in turn allow us to query the system in a more efficient and structured way.

\subsection{Management Application}
The IDChain Management application was built as a web \ac{SPA}.
We used a common frontend stack to build this application: \textit{React}\footnote{https://facebook.github.io/react/} for building the user interface and \textit{Redux}\footnote{https://http://redux.js.org/} for application state management.
By building the application using a SPA architecture, we are able to provide end-users a much-improved experience, mainly in navigation through the app, since no full page requests are required.
The \ac{SPA} architecture also enables to take advantage of already existing IDChain API, by directly accessing to obtain the data and control all the aspects of the system.

\section{Vanilla system}

The vanilla \ac{DHT} we present in this section, is the barebone \ac{client} for the other implementations in the next sections.

As mentioned before, the \ac{DHT} which we implemented is based on the Kad DHT library.
Kad provides a very thin basis for building DHT-based applications with sane defaults, providing also at the same time an extreme level of extensability and customization.

The nodes communication is done through JSON-RPC using the \ac{HTTP} protocol.

In order to launch every DHT client is necessary to provide a configuration file.

\lstinputlisting[label=lst:config, caption=Example DHT client configuration file., captionpos=b]{Examples/config-example.json}

A configuration file example is shown in Listing~\ref{lst:config}.
The fields \textit{nodeID}, \textit{hostname} and \textit{port} correspond to the node contact information in the DHT, and more specifically, in the case of the \textit{nodeID} field, the node identifier in the DHT network.
The \textit{storage} field is the folder where the DHT client will save the node data (key, values and routing table information). This points to a directory, because the Kad library by default uses LevelDB~\footnote{http://leveldb.org/} - an on-disk key-value store - for persistence.
In order to enter the DHT network is necessary to have another node contact information, which is defined in the \textit{seed} field.
We also defined the \textit{security} field, as an extension to the default configuration process of the Kad library.
This field contain all the options and information to deploy the chosen security mechanism.
In the case of the vanilla DHT, the sub-field \textit{mechanism} should be set to 'none'.
The other possible values are 'ca' and 'blockchain', for the CA-based mechanism and IDChain mechanism, respectively.

The \ac{API} our DHT client is the following:

\begin{itemize}
  \item \textit{start()} - start the DHT node, by connecting to a node in DHT network, which is specified in the seed field of the configuration file;
  \item \textit{stop()} - stop the DHT node;
  \item \textit{get(key)} - obtain the value associated with the specified key;
  \item \textit{put(key, value)} - store the specified value with the specified key;
\end{itemize}

Since we are building this DHT system using Node.js, in order to facilitate the access to our DHT client and easily build applications on top of it, is possible to obtain and require our DHT client as a \ac{NPM} module.

\section{CA-based system}

The next solution that we implemented uses the HTTPS protocol, for node communication.
This enables us to provide privacy, since the data transmitted is encrypted, authentication to the communicating nodes and ensures integrity of the transmitted messages.
In the typical HTTPS/TLS setup, as in web browsers, only the identity of the server is proved using X.509 certificates.
Nevertheless, is also possible to provide client-to-server authentication, by requiring that the client provide a valid certificate.

In our implementation, is necessary to provide mutual authentication, because we need to verify if the client trying join and perform operations in the DHT network is in fact authorized to do so.
Is also necessary to verify the server identity, because we want to be sure that we are bootstraping or exchanging messages with a node belonging to the DHT network.

We implemented a custom transport adapter on the Kad library, based on the HTTPS transport already built-in in Kad.
This transport is based on the HTTPS module provided by Node.js base libraries, more precisely the \textit{https.Server} and \textit{https.Agent} classes.

When configuring \textit{https.Server} instance we enable by default two options: \textit{requestCert}, which will make the server request a certificate from clients that connect and attempt to verify that certificate, and, \textit{rejectUnauthorized} which will reject any connection which is not authorized when verified against the certification path.
The \textit{https.Agent} instance also requires that we enabled the \textit{rejectUnauthorized} option, in order to verify the server certificate against the certification path.

Is also necessary to pass \textit{https.Server} and \textit{https.Agent} instances the node certificate, node private key and CA certificate bundle (which include the intermediary and root CAs certificates).
As can we see in Listing~\ref{lst:config-ca}, the \textit{security} field of the DHT client configuration file should contain the fields \textit{nodeCert}, \textit{nodeKey} and \textit{cacert}, which contains the paths to load the node certificate, node private key and the certificate bundle.
All this files should be in \ac{PEM}~\cite{rfc1421} format.
The loaded certificate should also contain the X509v3 Extension \textit{X509v3 Extended Key Usage} with the values \textit{Server authentication} and \textit{Client authentication}.

\lstinputlisting[label=lst:config-ca, caption=Example of security field in configuration file, captionpos=b]{Examples/config-example-ca.json}

As it is, this solution already allows to assert that the only authorized nodes can connect to the DHT network.
But we also want to verify that the nodes are not impersonating a different identity, that the one that are allowed to use.
Therefore, is necessary to encode the node's identifier in the certificate and perform the validation during the TLS handshake.
We decided to encode this information in the X509v3 Extension \textit{X509v3 Subject Alternative Name} as a DNS entry.
For sake of completeness, we also encoded in this extension the node host name and IP address.

In our custom transport in necessary to add this mechanism when performing a request to a node and when receiving a request from another node.

In the client side, we add a listener to the request socket object for the \textit{secureConnection} event.
This event is emitted after the TLS handshaking process for a new connection was successfully completed.
Our listener function checks if the node identifier encoded as a DNS entry in the Subject Alternative Name extension in the certificate is equal to message sender identifier, and if the certificate was authorized when performing the certification path verification.

% TODO: add pseudo code for mechanism

In the server side, we simply access the certificate when handling a new request, through the received request object and do the same verification as in the client side.

Is important to notice, that this verification takes place right after the TLS handshake process.
In Chapter~\ref{chapter:architecture}, our initial approach was to perform this verification mechanism during the handshake process, but the Node.js implementation does not provide the mechanisms to modify the handshake process.
Even thought, the benefits of performing this verification, even if after the handshake process, surpasses not doing it.

\section{IDChain system}\label{implementation:idchain}

\subsection{Smart contract}

\subsection{API}

\subsection{Application}
