\chapter{Evaluation}
\label{chapter:evaluation}

In order to evaluate the implemented solution, several tests were done to assess protocol correctness and measure system performance.
In Section~\ref{section:scenarios} we detail our evaluation process and the overall objectives we pretend to achieve in the evaluated scenarios.
Then, in Section~\ref{section:methodology} we describe the methods, tools and challenges we had to perform the evaluation.
Lastly, in Section~\ref{section:results} we present and discuss the solutions evaluation results.

\section{Evaluation Objectives and Scenarios}
\label{section:scenarios}

Our evaluation has an extended focus in the correctness of the implemented protocol.
But we also perform benchmarking of the all implemented solutions, in order to compare them.

Given the requirements presented in Section~\ref{architecture:requirements}, the following metrics were defined:

\begin{itemize}
  \item \textit{Response time for writes} – we will evaluate the system response time, as the number of write requests in the DHT increases;
  \item \textit{Response time for reads} – we will also evaluate the system response time, as the number of read requests in the DHT increases;
    % only error rate? add number of nodes storing the value as a metric also?
  \item \textit{Error rate} – this metric has distinct interpretations for read and write requests. In the case of the write requests, we analyze the number of nodes that stored the value, and define different error categories. In read requests, we consider that the request failed when is impossible to obtain a value.
\end{itemize}

Using these metrics, we performed load tests and functional security tests to the \ac{DHT}.
We performed two different types of load test: \textit{(a)} one client only issuing write requests, (b) one client only issuing read requests.
As summarized in Table~\ref{table:test-scenarios}, we run the tests for the different scenarios using a DHT network with 10 nodes deployed.
We conducted tests for each mechanism and write/read combination, where we varied the rate from 0.1 requests/s up to 100 requests/s in write tests, and from 1 request/s to 100 requests/s in read tests.
Only one node was setup to perform the requests, and each test was repeated 5 times.
The tests were executed over the length of several days, in order to minimize any potential effect related to varying network traffic.

\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{lllll}
    \multicolumn{1}{c}{\textbf{Test \#}} & \textbf{Mechanism} & \multicolumn{1}{c}{\textbf{Test Type}} & \multicolumn{1}{c}{\textbf{\# Number of nodes}} & \multicolumn{1}{c}{\textbf{\# Requests/second}} \\ \hline
    \multicolumn{1}{c}{1} & None (HTTP) & \multicolumn{1}{c}{Write} & \multicolumn{1}{c}{10} & \multicolumn{1}{c}{[ 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 40, 100 ]} \\ \hline
    \multicolumn{1}{c}{2} & CA-based (HTTPS) & \multicolumn{1}{c}{Write} & \multicolumn{1}{c}{10} & \multicolumn{1}{c}{[ 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 40, 100 ]} \\ \hline
    \multicolumn{1}{c}{3} & IDChain (HTTPS) & \multicolumn{1}{c}{Write} & \multicolumn{1}{c}{10} & \multicolumn{1}{c}{[ 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 40, 100 ]} \\ \hline
    \multicolumn{1}{c}{4} & None (HTTP) & \multicolumn{1}{c}{Read} & \multicolumn{1}{c}{10} & \multicolumn{1}{c}{[ 1, 2, 5, 10, 20, 40, 100 ]} \\ \hline
    \multicolumn{1}{c}{5} & CA-based (HTTPS) & \multicolumn{1}{c}{Read} & \multicolumn{1}{c}{10} & \multicolumn{1}{c}{[ 1, 2, 5, 10, 20, 40, 100 ]} \\ \hline
    \multicolumn{1}{c}{6} & IDChain (HTTPS) & \multicolumn{1}{c}{Read} & \multicolumn{1}{c}{10} & \multicolumn{1}{c}{[ 1, 2, 5, 10, 20, 40, 100 ]} \\ \hline
  \end{tabular}%
}
\caption{Test scenarios.}
\label{table:test-scenarios}
\end{table}

We also defined a metric for the smart contract evaluation:

\begin{itemize}
  \item \textit{Monetary cost} – we will also measure the cost of executing each smart contract function, with a variable number of entities.
\end{itemize}

This test was executed in a local machine, by calculating the \textit{gas} cost of executing every smart contract function in the \ac{EVM}.

Finally was also necessary to evaluate the DHT protocol correctness under a number of possible scenarios, from a security analysis perspective.
In Section~\ref
\section{Evaluation methodology}
\label{section:methodology}

% TODO: section summary

\subsection{DHT Nodes deployment}

%TODO: falar do tamanho dos k-buckets e em que medida isso influencia o sistema

The DHT nodes were deployed on Digital Ocean\footnote{https://www.digitalocean.com/}, distributed across several different datacenters.

We deployed 9 nodes, one node for each of the following datacenters: New York City 1 (NYC1), New York City 3 (NYC3), San Francisco 1 (SFO1), Toronto 1 (TOR1), London 1 (LON1), Frankfurt 1 (FRA1), Bengalore 1 (BLR1), Amsterdam 2 (AM2) and Amesterdam 2 (AM3).
The 9th node which corresponds to the benchmark client was located in Lisbon.

The node that was defined as bootstrap node in all nodes configuration was the node located in the NYC1 datacenter.

All the nodes used a \acp{VM} with the same specs: 1vCPU, 512 MB RAM, 20 GB SSD disk space, running Ubuntu 16.04.3 x64.
The nodes used Node.js v8.2.1, PostgreSQL 9.5.8 and Ethereum testrpc client v4.1.3.

The benchmarking client was run on a server with Dual Intel Xeon E5-2640@2.00GHz CPU with a total of 32 cores, 128GB of RAM and running Debian 8.2.
The versions of the software used were equal to the Digital Ocean nodes.

\subsection{Tests configuration and tooling}

In order to perform the load test evaluation of systems, was necessary to build a set of scripts.
We built two different scripts for write and read requests.
The write request script receives three parameters: DHT mechanism to use, total number of requests and demanded request rate per second.
This script was ran using the following process:

\begin{enumerate}
  \item Deploy all 9 nodes;
  \item Run the script in benchmarking node with the given parameters.
  \item When the script finishes, delete the all nodes cached data;
  \item Repeat the process.
\end{enumerate}

Is necessary to delete the node cached data between runs, in order to the tests to run in a clean state DHT, withou any data written to.
The script outputs each request start/completion time and number of nodes that stored the written value in a CSV file.

The read request script receives three parameters: DHT mechanism to use, total number of requests and a list of demanded request rates per second.
This script - on contrary to the write script - in each execution will perform several test iterations, increasing the demanded request rate, according to the received list of demanded requests.
We choose this approach in read script because it's not necessary to clear the node data between executions, and allow us to perceive the system performance with an increasing number of requests.

In Tables~\ref{table:total-requests-demanded-rate-writes} and~\ref{table:total-requests-demanded-rate-reads} we present the demanded request rate and total number of requests that were done, in write script and read script executions, respectively.

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccccccccccc}
  \textbf{Demanded Request Rate (req/s)} & 0.1 & 0.2 & 0.5 & 1 & 2 & 5 & 10 & 20 & 40 & 100 \\ \hline
  \textbf{\# of Requests per run} & 720 & 1440 & 3600 & 3600 & 3600 & 20000 & 20000 & 20000 & 20000 & 20000 \\ \hline
  \textbf{Total Requests} & 3600 & 7200 & \multicolumn{3}{c}{18000} & \multicolumn{5}{c}{100000} \\ \hline
\end{tabular}%
}
\caption{Number of write requests performed according to demanded request rate.}
\label{table:total-requests-demanded-rate-writes}
\end{table}

\begin{table}[htb]
\centering
\begin{tabular}{cccccccc}
  \textbf{Demanded Request Rate (req/s)} & 1 & 2 & 5 & 10 & 20 & 40 & 100 \\ \hline
  \textbf{\# of Requests per run} & \multicolumn{7}{c}{10000} \\ \hline
  \textbf{Total Requests} & \multicolumn{7}{c}{50000} \\ \hline
\end{tabular}
\caption{Number of read requests performed according to demanded request rate.}
\label{table:total-requests-demanded-rate-reads}
\end{table}

In order to write values to the DHT, we pre-generated several keys by hashing an increasing integer counter, using a SHA-1 function.
The object stored under each key in the DHT, was always the same: a JSON file containing a structure similar to values that the Global Registry stores with a filesize of 827 bytes.

The certificates that were used in the test nodes were created using OpenSSL\footnote{https://www.openssl.org/} and cfssl\footnote{https://github.com/cloudflare/cfssl} command-line tools, and respect the certificate requirements that we referred in Sections~\ref{implementation:idchain} and~\ref{implementation:ca-based}.
In the case of the CA-based mechanism tests, we used a two-tier architecture, with a root CA and a intermediate CA.

\subsection{Evaluation challenges}

Our benchmarking client presented performance limitations when executing our test scripts, that taken into consideration when analyzing the results obtained.
Since, our DHT is based in Node.js runtime, there is limitation in the number of concurrent connections that can be done.
The node running in the Digital Ocean datacenters, had by default a maximum number of open file descriptors equal to 1024.
We tried to increase the value, but the limitations persisted.
This causes an enormous limitation when executing the tests, because the main bottleneck was the benchmarking client.

\section{Evaluation Results}
\label{section:results}
In the following sections we discuss the evaluation results.
The Section~\ref{section:load-tests} focus in read and write load tests, and Section~\ref{section:smart-contract-tests} focus in smart contract execution metrics.

\subsection{Load tests}
\label{section:load-tests}

\subsubsection{Write requests}

The Figures~\ref{fig:demanded-request-rate}–~\ref{fig:stored-ratio-https-bc} represent the write load test evalution results.

The graph from Figure~\ref{fig:demanded-request-rate} represent the effective request rate in function of the demanded request rate, for each of the implemented solutions.
Each point in the graph, illustrate the average request rate of the 5 different test executions performed, for the specific demanded request rate.
In the Figure legend the \textit{http} value represent the vanilla DHT implementation, the \textit{https} value represent the CA-based DHT implementation and \textit{https-bc} represent the IDChain DHT implementation.
For instance, the point (0.1, 0.1), in any of the solutions, represent the average request obtained (0.1 req/s) for 5 repetitions performed for this test, demanding a request rate of 0.1 req/s.
In Figure~\ref{fig:demanded-request-rate} is possible to verify that in the [0.1, 10] request/s demanded request rate, all the three solutions have an approximated equal effective request rate, which means that the client is able to keep up with the demanded request rate.
In the ]10, 100] request/s demand request rate range, thevanilla DHT implementation outperforms the CA-based and IDChain solutions, by being able to keep up more closely with the demanded request rate.
The vanilla DHT implementation is able to perform~$\approx$ 90 requests/second, where the CA-based and IDChain solutions become saturated at~$\approx$ 17 requests/second.
This shows us that the HTTP-based solution is capable of outperforming clearly the HTTPS-based solutions, at the cost of didn't provide any security aspects in the nodes communication.
The message overhead of the HTTPS handshake protocol, limits the request rate capacity of the CA-based and IDChain solutions.
Is important to notice, that could be possible to increase the request rate capacity of the HTTPS-based solutions, if TLS Session Resumption and Keep-Alive connections are activated in HTTPS.
We are also able to conclude that the IDChain solution is a viable solution performance-wise to the CA-based solution.
It seems that increased message header overhead and the requests performed to the IDChain API, doesn't incur in a substantial cost to the effective request rate the client is able to perform, in comparison with the CA-based solution.

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.4]{Figures/evaluation/request-rate-writes-linear.pdf}
  \caption{Demanded request rate.}
\label{fig:demanded-request-rate}
\end{figure}


The graph from Figure~\ref{fig:average-response-time} represent the average request response time in function of the effective request rate, for each of the implemented solutions.
Each point in the graph, illustrate the average request response of the 5 different test executions performed for each of the demanded request rates, in function of the effective request rate.
We can draw similar conclusions to those of the previous discussed figure: the HTTP-based implementation clearly outperforms the HTTPS-based implementations, by having, in average,~$\approx$ 2 times faster response times.
This results of the aforementioned added message overhead of the HTTPS handshake protocol.
The average response time of the CA and IDChain based DHT implementations remain approximately constant, only increasing when an~$\approx$ 15-17 requests/second effective request rate is achieved, which correspond to a demanded request rate in the ]10, 100] requests/second range.
In the case of the HTTP-based implementation, the average request response time also remained constant with an increasing load, only increasing drastically to an average response rate of 23552.88 ms when an effective request rate of 90.83 requests/second - which corresponds to a demanded request rate of 100 request/second - is achieved.
This result is due to the fact that when performing that effective request rate, the test DHT client becomes saturated with inbound and outbound requests, consequently the average response time drastically increases.
This only occurs in the HTTP-based implementation, because the effective request rate is much higher than in HTTPS-based solutions, which means that the bottleneck is in the client capacity of processing all inbound and outbound requests.

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.4]{Figures/evaluation/average-response-time.pdf}
  \caption{Average response time.}
  \label{fig:average-response-time}
\end{figure}


The graph from Figures~\ref{fig:stored-ratio-http},~\ref{fig:stored-ratio-https} and~\ref{fig:stored-ratio-https-bc} illustrate the number of nodes that stored the value in each write request, in function of the demanded request rate for each implementation.
In order to be easier to interpret the data, each plot in the graph represents a range of different number of nodes that stored the information.
We represent the values in the \textit{y-axis} as the ratio between the number of requests with the defined "stored" variable and the total number of requests performed for the associated demanded request rate.

Is possible verify that in the HTTPS-based implementations that each value written to the DHT is almost always stored in 5 different nodes, intermittently being stored in 4 nodes.
In the case of the HTTP-based implementation, in the [0.1, 40] requests/second range of demanded request rate, the obtained results are equal to those of the HTTPS-based solution.
When the demanded request is increased to 100 requests/second, the number of requests in which the value is stored in 5 nodes decreases to 36.1\%, and the number of failed writes (values that aren't stored in any node) increases to 63.8\%.
Those results in the HTTP case are closely related with the conclusions that we drawn out from Figure~\ref{fig:average-response-time}.
Since there is a bottleneck in the client capacity of processing inbound and outbound requests, some requests will invariably timeout and the values will not be stored in any node.

\begin{figure}[htb]
  \centering
  \begin{minipage}[t]{.45\textwidth}
    \centering
    \includegraphics[width=.8\textwidth,scale=0.4]{Figures/evaluation/stored-ratio-http.pdf}
    \caption{Number of nodes storing each value, in vanilla DHT.}
\label{fig:stored-ratio-http}
  \end{minipage}\hfill
  \begin{minipage}[t]{.45\textwidth}
    \centering
    \includegraphics[width=.8\textwidth,scale=0.4]{Figures/evaluation/stored-ratio-https.pdf}
    \caption{Number of nodes storing each value, in CA-based solution.}
\label{fig:stored-ratio-https}
  \end{minipage}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.4]{Figures/evaluation/stored-ratio-https-bc.pdf}
  \caption{Number of nodes storing each value, in IDChain solution.}
\label{fig:stored-ratio-https-bc}
\end{figure}

\subsubsection{Read requests}

\subsection{Protocol correctness}
\label{section:protocol-correcteness}

In order to evaluate the CA-based and IDChain DHT protocol implementations, is necessary to define the threat model.
Two of the main objectives of the presented solutions are to \textit{close DHT participation} and \textit{ensure communication privacy, integrity and authenticity}.

Taking in consideration that we are dealing with a DHT system, that are some critical DHT processes that could be potential attack vectors.
We will evaluate if each one of those processes, and analyze how attack vectors are mitigated by our solutions.

A node bootstrap in the DHT, is one of the critical DHT processes which could be targeted.
Each DHT node entering the network must be sure that is entering it through a trustable node, and is not being tricked into entering a DHT network with malicious nodes.
Every DHT node must also ensure that every node bootstraping through them, is allowed to enter the network.
This is also what enable us to provide access control to the DHT network, which take us in the direction of solving the objective of close DHT participation.
Also, is necessary to ensure privacy, integrity and authenticity in the DHT network message routing, because we want to prevent any external interference in the DHT network - as for example, resorting to MITM attacks - and provide confidentiality in the data exchanged inside the DHT network.
All of these aspects, are closely related to the node communication establishment.

\subsubsection{CA-based solution evaluation}

The CA-based solution is capable of mitigate each of the aforementioned attack vectors.
The TLS/HTTPS protocol with mutual authentication is able to enforce the routing messages privacy, integrity and authenticity, in the two-ways of the communication channel.
Also, using X.509 certificates containing the DHT node identifiers, issued by a root or intermediate CA, we can ensure during the bootstrap process that we are effectively connecting to a DHT composed of trusted nodes.

% falar de traidores?
This solution is also able to ensure that each trusted node — in case of going rogue — is not able to steal other node identifier.

One possible vulnerability of the mechanism is related with performing the extra verification of node identifier encoded in the certificate.
As we are only able to perform the verification after the TLS handshake — when the \textit{onSecure} event is called) — there is a small time frame where data could be exchanged with potential malicious nodes.

But still, this attack could only be performed by a trusted node that decides to go rogue, since the verification of the node's certificate against the certification path is performed as part of the TLS handshake process.

\subsubsection{IDChain solution evaluation}

As in the CA-based solution, the IDChain solution is also capable of mitigate the same attack vectors, since the solution also uses TLS/HTTPS protocol for node's communication.
This solution therefore, also suffers for the same problem as the previous evaluated solution — we are only to perform the certificate peer validation after the TLS handshake process.
In this case is also necessary to perform a request to the IDChain API, which slightly increases the time frame where data could be exchanged with a potential malicious node.
In this case, the attack could be also performed by malicious nodes from outside the DHT network, since we are using self-signed certificates and a certification path to verify the certificates against don't exist.

% falar de traidores?
This solution is not using TLS mutual authentication due to the Node.js TLS restrictions we encountered, and was necessary to add a complementary scheme in order to perform TLS clients authentication.
This solution is vulnerable to one attack that could performed by a node from the DHT network, that decides to go rogue.
This attack mechanism is similar to a replay attack:

\begin{enumerate}
  \item The node that decides to go rogue performs several message exchanges with the target node, and stores the target node certificate and each 'challenge' and 'challenge signature' fields from the messages sent by the target node.
  \item The rogue node now has a series of timestamps/challenges and challenge-signature fields, that could be used to impersonate the target peer identity, during a limited time frame.
\end{enumerate}

\subsubsection{Sybil attack resistance}

\subsection{Smart contract tests}
\label{section:smart-contract-tests}

\subsubsection{Monetary Costs}

