\chapter{Related Work}
\label{chapter:relatedwork}
This section addresses the state of the art of the research topics relevant to our proposed work: P2P Networks, DHT security considerations, Public Key Infrastructure, Blockchain and the Bitcoin protocol.

\section{P2P Networks}

\ac{P2P} networking is a distributed systems architecture where equal and autonomous entities (peers) are interconnected and form a network with the objective of sharing distributed resources.
The \ac{P2P} network model allows peers to self-organize into a network topology that is able to deal with failures and adapt the network topology with a variable rate of joining and exiting nodes (churn rate).~\cite{GuptaA11}
\ac{P2P} systems networks are usually categorized as \textit{Structured} or \textit{Unstructured}~\cite{Lua2005}.

\subsection{Unstructured} In an Unstructured overlay network, nodes join the network by connecting to other nodes without prior knowledge of the topology, therefore creating a random network structure.
Peers search for content using flooding as a querying mechanism to other nodes' content.
Despite being resilient for locating highly replicated content and to a high churn rate, the flooding mechanism is not suitable for locating rare content and it does not scale well for a high number of nodes due to the high load generated by the queries.
\ac{P2P} systems like Gnutella~\cite{gnutella} use an unstructured overlay network.

\subsection{Structured} Structured overlay networks use node identifiers to organize the network and maintain the overlay network topology when new nodes join or exit the network.
The content is placed in specific locations, therefore allowing more efficient queries.
The most common structured overlay pattern is the \acl{DHT}.
\ac{DHT} systems assign random node identifiers to peers from a large identifier space.
Datasets are also assigned unique identifiers from the same identifier space, called \textit{keys}, by applying a cryptographic hash function to the data.
This allows for the creation of an index, where each key identifies the position of the corresponding dataset in the network, therefore making it possible to retrieve the data from a live peer in the network.
Peers maintain routing tables that store the neighbor peers' identifier and IP address in the identifier space, which are necessary to forward routing messages across the overlay network until they reach the destination node.
Several DHT-based solutions exist which implement different overlay network structure and routing schemes.

Chord~\cite{Stoica2001} and Pastry~\cite{Rowstron2001} organize nodes in a circular identifier space, where each node is responsible for a section of the circular identifier space and for forwarding routing and lookup messages along the neighbor nodes, until it reaches the node responsible for the given key.
Kademlia~\cite{Maymounkov2002} maps nodes into a balanced binary tree recurring to the XOR operation as a distance metric to perform parallel lookups. A more comprehensive description of Kademlia is given in the next sub-section.

\subsection{Kademlia} In Kademlia, a 160-bit uni-dimensional address space is used for node and key identifiers, which could be represented as a balanced binary tree.
The key-value pairs are stored in the node closest to the key, according to the distance metric.
Routing in Kademlia is based on the XOR distance metric, \(d(a,b)=a \oplus b\), for the notion of distance between two identifiers.
This metric has two useful properties:
\begin{itemize}
  \item It is \textbf{unidirectional}, meaning that for a given distance there is only one identifier at that distance. Consequently, all lookups for the same key converge along the same path, so it is possible to do \textit{caching} of keys;
	\item It is \textbf{symmetric}, which allows the node to update the routing table with the received search messages.
\end{itemize}
Messages may be sent to any node of an interval, making it possible to send messages in parallel, first reaching the node with smaller latency.
In order to route query messages, nodes need to keep a list of \textit{k} nodes for each sub-tree where they are not present.
These lists are called \textit{k-buckets} and are sorted by time last seen, i.e time elapsed since last message.
k-buckets have a size \textit{k}, where \textit{k} is chosen such that it is very unlikely that all nodes fail within an hour.

Every message a node receives, triggers an update in the k-bucket for the sender identifier. If there is available space in the k-bucket, the new identifier is inserted at its tail – or if already present – moved to the tail.
If the identifier is new and the bucket is full, the oldest element is pinged.
If it responds, the node is moved to the tail of the list and the new one is discarded.
Otherwise, it's removed and the new node is placed at the tail.
This provides resistance to denial of service attacks, because as the routing table favors old nodes, it is not possible to flush them by flooding the DHT with new nodes.

Kademlia needs to maintain a basic routing table by using k-buckets, and maintaining information for each sub-tree, knowing at least one node for each of the sub-trees.
When a new node \textit{b} joins and contacts a node \textit{c}, \textit{b} adds \textit{c} to a k-bucket (if full, the k-bucket is split between the two) and performs a lookup for himself.
Then \textit{b} refreshes k-buckets further away than its closest neighbor, therefore populating its own k-buckets and inserting himself into other k-buckets' nodes.
Since key-value pairs may expire and nodes with stored values may leave, Kademlia is a \textit{soft state} system, and therefore needs data republishing.

Data republishing is done by republishing key-value pairs every hour.

\section{\ac{DHT} security considerations}
There are several security considerations~\cite{Urdaneta2011} to take into
account when building a \ac{DHT}. They could be summarized into four categories:
\begin{itemize}
    \item \textit{Routing Attacks}
    \item \textit{Storage and Retrieval Attacks}
    \item \textit{Sybil Attack}
    \item \textit{Eclipse Attack}
\end{itemize}

\subsection{Routing Attacks} \label{ssec:routing-attacks}
Request routing is an essential component in any \ac{DHT}, so it is critical that
routing tables are correct in \ac{DHT} nodes. Since each node has to maintain its
own routing tables and update them accordingly, there are multiple attack
vectors that an attacker can take advantage of~\cite{Castro2002}:

\textit{Incorrect Lookup Routing}. A malicious node could forward lookups to an
incorrect or non-existent node.

\textit{Incorrect Routing Updates}. Since each node builds its routing table
using information from other nodes, a malicious node could corrupt the routing
tables of other nodes by sending incorrect updates.

\textit{Network Partition}. In order to bootstrap into the \ac{DHT} network, a node must contact some participating node. This makes the node vulnerable to entering an incorrect network.
The first node to be contacted may redirect the new node to a different partition, under malicious control.

\subsection{Storage and Retrieval Attacks}

A malicious node may be able to attack the underlying storage layer of the \ac{DHT}.
For example, it might claim to store data when asked, but then refuse to
serve it to clients.
Dealing with this attack requires the use of data replication, but it must be
handled so that no single node is responsible for replication or
facilitating access to the replicas, i.e avoid single points of
responsibility.
Clients should be able to determine the correct nodes to contact for replicas and obtain the data from these replicas, as a way to prevent single points of responsibility.

Kademlia prevents this sort of attack, because it does parallel searches and all the searches for a given identifier converge on the same path. Combined with data republishing and replication, the client may contact several nodes to ensure the data correctness.

\subsection{Sybil Attack}


The Sybil Attack is an attack that exploits a
distributed system when it fails to guarantee that distinct identities refer to
distinct entities~\cite{Douceur2002}.
In a \ac{P2P} system - like a \ac{DHT} - if an attacker
controls a fraction of the node identifiers, it is possible to create a collusion
of malicious nodes in the \ac{DHT} and even pollute the routing tables of honest
nodes.
A Sybil Attack amplifies the effect and reach of other attacks, such as the ones described earlier.
The Sybil Attack is a real threat to any overlay network, and there is enough evidence that this attack is possible in real deployed networks, as BitTorrent Mainline \ac{DHT}~\cite{Wang2012}.

The Sybil Attack defense mechanisms can be sub-divided in the following categories:

\subsubsection{Centralized certification}
Douceur argues that the only way to have a unique direct relation between an
identifier and an entity is by having a central trusted authority~\cite{Douceur2002}.

One proposed solution is to use certified node identifiers~\cite{Castro2002} issued by a trusted \ac{CA} that assigns node identifiers and signs node identifier certificates.
Each certificate binds a node identifier to a public key and an IP address.
The inclusion of the IP address prevents an attacker from moving the certificates across several nodes, minimizing this way the number of attacker nodes.
In order to avoid an attacker from obtaining several node identifier certificates, these certificates must be bought from the \ac{CA} entity.

Even though this solution allows control over who joins the network, it has the disadvantage of requiring a trusted centralized entity to manage the node identifier attribution.
%In our view, the cost of this solution (cost of certificates and inability to change IP address) makes it unfeasible for most public \acp{DHT}.

\subsubsection{Network characteristics}
One proposed solution that uses network characteristics is the \textit{net-print}~\cite{Wang2005} mechanism.
The \textit{net-print} are the node physical characteristics: node default router IP address, \acs{MAC} address and vector of \ac{RTT} measurements between the node and a set of routers (landmarks).
The net-print data can be easily verified by other nodes, by directly measuring the net-print of the node and comparing it with the claimed net-print.
This prevents possible sybil attacks by malicious nodes.
A problem in this mechanism are variable network conditions, that may cause the identity verification to fail, since the net-print values reported and the directly measured values would be different.
A tolerance in value deviation could be a possible solution, but this could diminish the security efficiency of the system.

Bazzi et al.~\cite{Bazzi2005} also proposed a sybil defense mechanism that leverages network characteristics to create network coordinates.
The proposed solution tries to solve the \textit{group distinctness problem}, i.e determining the number of distinct entities in which a group of identities reside.
By assuring that, for instance, in two separate groups of identities, if any two identities chosen from different groups are distinct, then it is possible to achieve redundancy in the execution of a remote operation by sending the operation to the two groups.
Each entity is located at a point in the geometric space (\textit{d}-dimensional Euclidean space or a sphere), therefore the transmission time of a message between two points A and B gives an upper-bound on the distance \textit{d(A,B)} between the points.
This solution takes into account the following assumptions:
\begin{itemize}
	\item the distance between two points satisfies the metric properties of a symmetry and triangle inequality;
	\item the distance between a pair of points is a non-decreasing function of roundtrip delay between them.
\end{itemize}
The system model considers a set of \textit{beacons} and a set of \textit{applicants}, which all together constitute the set of \textit{participants}.

This system comprehends two essential elements: \textbf{geometric certificates} and \textbf{group distinctness test}.

% confirmar esta frase
A \textit{geometric certificate} is a set of signed distance values between the beacons and the applicants, calculated by applicants and beacons responding to probe messages.
The \textit{group distinctness test}, for instance, could be a \textit{two-distinctness test} represented as a function \(D: C\times C\rightarrow \{true, unknown\} \), where \textit{C} represents a geometric certificate. If by applying \((c1,c2)\) to the function the result is \textit{true}, then the entities with these geometric certificates are distinct.
The main advantage of this system is that it provides a good basis for a redundancy protocol, guaranteeing that identities in different groups are not controlled by the same entity.
The major problem with this system is that it can be easily circumvented, if an attacker uses several distributed nodes that will be assigned to different groups.
Also the system is tested on a network that could not exhibit the same delay characteristics as of the Internet.

\subsubsection{Computational puzzles}

S\textbackslash{Kademlia}~\cite{Baumgart2007} proposes a \textit{dynamic crypto puzzle} that attaches a barrier to the generation of several node identifiers.
After the node identifier is generated from hashing the user public key, a random number \textit{N} is choosen and the value of \textit{P} is calculated accordingly to the function \(P := Hash(NodeID \oplus N)\), where \(\oplus\) is the XOR operation.
This function is repeatedly calculated by changing the value of \textit{N}, until there is a value of \textit{P} that is preceded by \textit{c} zero bits, where \textit{c} is a constant that can be adjusted to increase or reduce the difficulty of the crypto puzzle.
The verification of the crypto puzzle is done every time a node receives a signed message.

Computational puzzles represents a decentralized solution that can effectively limit the number of Sybil identities.
But it has the disadvantage that it is a solution that can only mitigate the attack and not impede it, and forces honest nodes to spend computational resources to puzzle solving.

Several other solutions exist that use \textit{social networks}~\cite{Yu2008}\cite{Yu2010} or \textit{game theory}~\cite{Margolin2008}. These solutions require an \textit{a priori} social network or social relationships between participants or, in the case of game theory, the use of economic incentives through the implementation of a currency, turning these solutions infeasible in the scope of this project.

\subsection{Eclipse Attack}
In an Eclipse Attack~\cite{Singh2006} malicious nodes collude with the objective of deceiving other nodes into adding them to their neighbor set, poisoning their routing table.
If successful, the attacker can be ensured that all messages from that node to the overlay network and vice-versa are routed through at least one malicious node.
This gives the malicious node the ability to block and inject messages, providing an incorrect view of the overlay network to the honest nodes or even drive a denial of service attack.
It is possible to assume that an Eclipse attack is closely related to a Sybil attack, but even a small number of malicious nodes with different identities could be able to produce an Eclipse attack.
A specific security mechanism is required to prevent this sort of attack.
In order to impede the attack some of the main requirements are:
\begin{itemize}
	\item that the nodes be unable to choose their node identifier, which protects against Eclipse attacks that try to target a specific node or region of the routing table;
	\item increase the difficulty of influencing over other nodes' routing table, difficulting the capacity of an attacker block honest node's correct view of the overlay network.
\end{itemize}
The previously presented \textit{Routing Attacks} are closely related with Eclipse attacks, so the solutions presented in this section will also help mitigate those attacks.

Singh et al.~\cite{Singh2006} presented a solution that is based on the fact that the \textit{in-degree} of malicious nodes is higher that the average in-degree of honest nodes.
This way, as a result it is possible to prevent an Eclipse attack by choosing nodes with an \textit{in-degree} below a certain threshold.
But malicious nodes may connect to honest nodes in order to increase their in-degree, so it is also necessary to bound the out-degree of the nodes.
This is implemented by building an anonymous distributed auditing mechanism, where every node challenges anonymously, each member of the neighbor set for their \textit{backpointer set}: a list of the nodes that contain the challenger node in their neighbor set.
If entries count in the backpointer set is bigger that the in-degree bound, or the challenger node doesn't appear in the backpointer set, the challenged node is removed from the challenger node neighbor set.
A similar procedure is done to check the out-degree bound, by verifying if the neighbor set size of a node's backpointer set members is below the out-degree threshold.
In order for this system to work, the challenger node must remain anonymous, or a malicious node could fake the response to a challenge, by creating a fake backpointer set with a size below the in-degree threshold and adding the auditing node.
So, it is necessary to relay the challenge through an \textit{anonymizer node} to hide the challenger identity.
Since this anonymizer node belongs to the network and could be malicious, several audits must sent through different anonymizers at random times and the audit response must be digitally signed.
A node \textit{A} that challenges node \textit{B}, selects a node randomly from the \textit{l} numerically closest nodes to the hash H(B).
The expected fraction of malicious nodes in this subset is equal to the fraction of malicious nodes in the overlay network.
Considering that in the network, every node is considered malicious if it answers less that \textit{k} out of \textit{n} challenges correctly, the following probabilities could be calculated:
\begin{itemize}
	\item \textbf{Honest node is considered malicious:}
	\begin{equation}
		\sum_{i=0}^{k-1} \binom{n}{i} f^{n-i} (1-f)^{i}
	\end{equation}
	\item \textbf{Malicious node passes the audit undetected:}
	\begin{equation}
		\sum_{i=0}^{k-1} \binom{n}{i} [f+(1-f)c/r]^{i} [(1-f)(1-c)]^{n-i}
	\end{equation}
\end{itemize}
Where \textit{f} is the fraction of malicious nodes in the overlay network, \textit{c} is the probability of malicious nodes answering the challenge, and \textit{r} is the ratio of the size of the true set (real backpointer set) versus the maximum allowed size. This calculation is needed, since a malicious node may adopt a strategy where he responds with only a subset of his backpointer set with a size equal to the maximum allowed size.
The authors state, as an example, in a scenario that a node is considered malicious if he answers less than \textit{k} out of \textit{n} challenges, with \(f \leq 0.25\), \(n=24\), \(k=12\) and \(r \geq 1.2\) the false positive probability is around 0.2\% and malicious nodes are detected with a probability of at least 95.9\%.

The advantage of this system is that it leverages the overlay network primitives to build a simple and efficient algorithm to detect and prevent Eclipse attacks. But the system is only effective with a small degree threshold, which increases the lookup time when there are no attacks taking place.

S\textbackslash{Kademlia} proposes a static crypto puzzle to generate node identifiers that is based on repeatedly generating a key pair and double hashing the public key, until there is \textit{c} preceding zero bits in the hash.
This solution only deals with the node identifier generation, since it randomizes the process and doesn't allow the node to choose a node identifier freely.
Therefore, this solution is only efficient in situations where a targeted Eclipse attack may occur. Used in conjuction with the aforementioned dynamic crypto puzzle it will also limit sybil attacks.

\section{Public Key Infrastructure}
Through encryption and digital signatures~\cite{Rivest1978}, public-key technology~\cite{Diffie1976} provides:
\begin{itemize}
  \item \textbf{Confidentiality}: the data must not be made available or disclosed to unauthorized users;
  \item \textbf{Non-repudiation}: is a property that ensures that if a user signed data, he cannot deny signing that data. This prevents an entity from denying having performed a specific action;
  \item \textbf{Authentication}: is the process of confirming the identity of a user, preferentially without sending secret information through the network;
  \item \textbf{Integrity}: is the property that guarantees that data has not been modified. By using digital signatures it is possible to check if the digitally signed data has been altered since it was signed.
\end{itemize}

A \acl{PKI}~\cite{choudhury2002public}\cite{Entrust2000} is a system that provides public-key encryption and digital signature services. It is structured as a framework that consists of security policies, encryption mechanisms and applications, with the propose of generating, storing and managing keys and certificates.

Therefore a \ac{PKI} must manage the whole lifecycle of each key pair~\cite{Buchmann2013}. This lifecycle comprehends several tasks necessary to provide a secure management of these keys, and can be divided in three different phases: \textit{key generation}, \textit{key usage} and \textit{key invalidation}.

In the \textit{key generator} phase, it is necessary to provide users with the ability to generate key pairs. These key pairs may be generated by the user, preventing the private keys from being disclosed to unauthorized parties, but this key generation may not be possible in computationally restricted devices. So it is possible for a \ac{PKI} infrastructure to generate key pairs for the user, but in this case, as a third-party generates the keys, the user's private keys will also be known by the third-party which could bring some security concerns.

The \textit{key usage} phase is one of the most important phases in the key pair lifecycle, since it has the task of \textit{making the public keys available to users.}: it is not only necessary to publish the keys, it is also necessary to verify their authenticity and validity. If an attacker is able to replace an user's public keys with his own public keys, he could impersonate that user and therefore decrypt messages sent to the user or sign documents on behalf of the user. In the key usage phase, there is also a task of managing key backups. The use case of key backups is the ability to provide users a mechanism for key recovery for when they lose the data's private decryption key and need to access the encrypted data. As in the \textit{key generation} phase, for a \ac{PKI} infrastructure to be able to provide this backup mechanism, it will be necessary to store the user's private keys, which could bring potential security issues.

The last phase in the key pairs lifecycle is the \textit{key invalidation}. One of the main tasks of the \ac{PKI} in this phase is dealing with public keys that became insecure, due to a broken cryptosystem or if stolen. Two courses of action are possible in this scenario: \textit{destroy} or \textit{archive} the key. In the case of invalid public keys, they can be deleted since they cannot be used again safely, but private keys may be archived, so it may be possible to still access data that was encrypted with the corresponding public key.

One of the fundamental elements of the \ac{PKI} infrastructure are the certificates.
Certificates provide an authenticity proof for public keys, by binding an entity to a specific public key, through the signature of a third-party. If the user requesting the public key trusts the third-party, verifying the digital signature of the certificate is sufficient to ensure the user of the authenticity of the public key.

Usually the structure of the certificate contains at least:

\begin{itemize}
  \item \textbf{Name of the entitity};
  \item \textbf{Public key} bound to the entity;
  \item \textbf{Cryptographic algorithm} used by the public key;
  \item \textbf{Certificate serial number};
  \item \textbf{Certificate validity period};
  \item \textbf{Issuer of the certificate};
  \item \textbf{Restrictions on the usage of the public key}.
\end{itemize}

Several solutions that implement a \ac{PKI} infrastructure exist: Certificate Authorities and Web of Trust.

\subsection{Certificate Authorities}
\acp{CA} are the main model of \ac{PKI} used nowadays.
In a \ac{CA} model of \ac{PKI} there is a third party that authenticates entities by issuing a digital certificate.

The X.509 standard~\cite{rfc5280}\cite{itut38895} is one of the most used \ac{CA}-based \ac{PKI} infrastructures nowadays, and it is supported by several communication standards like \acs{HTTPS}, \acs{SSH} and \acs{TLS}/\acs{SSL}.

It comprehends the following components:
\begin{itemize}
	\item \textbf{End entity}: users of \ac{PKI} certificates or end user systems that are the subject of a certificate;
	\item \textbf{Certification Authority}: authenticates entities in a transaction;
	\item \textbf{Registration Authority}: system responsible for the interactions between the end user and \ac{CA}. It receives entity requests, processes and validates them, directs them to the \ac{CA} for posterior processing and forwards the processed certificates to the user;
	\item \textbf{\acsp{CRL} issuer}: generates and stores \acp{CRL};
	\item \textbf{Repository}: stores and distributes \acp{CRL} and certificates to the end users.
\end{itemize}

The \textit{X.509 certificate} contains several fields as depicted in Figure~\ref{fig:x509-certificate}:

\begin{itemize}
	\item \textbf{tbsCertificate}
		\subitem \textbf{version}: describes the version of the encoded certificate;
		\subitem \textbf{serialNumber}: unique positive integer assigned by the \ac{CA};
		\subitem \textbf{signature}: describes the signature algorithm used by the \ac{CA} to sign the certificate;
		\subitem \textbf{issuer}: specifies the entity that signed and issued the certificate. Contains a ASN.1 string called \textit{distinguished name} (DN) that describes a hierarchical name composed of several attributes such as country name, organization, etc;
		\subitem \textbf{validity}: specifies the validity period of a certificate, and contains two date fields - \textit{notBefore} and \textit{notAfter} - that indicate, respectively, a point in time where the certificate was not valid yet and a point in time where the certificate is not valid anymore;
		\subitem \textbf{subject}: describes the entity that owns the certificate and is associated with the public key stored in the \textit{subjectPublicKeyInfo} field;
		\subitem \textbf{subjectPublicKeyInfo}: this field contains two sub-fields - \textit{algorithm}, used to identify the algorithm which the key uses, and \textit{subjectPublicKey} which contains the subject public key;
		\subitem \textbf{issuerUniqueID/subjectUniqueID}: unique identifier for the subject and issuer;
		\subitem \textbf{extensions}: sequence of one or more certificate extensions that allow to add additional attributes associated with the certificate, providing support for additional \ac{PKI} processes.
	\item \textbf{signatureAlgorithm}: contains the identifier of the cryptographic algorithm used to sign the certificate;
	\item \textbf{signatureValue}: contains a digital signature of the \textit{tbsCertificate} content;
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{Figures/x509-certificate.pdf}
    \caption{X.509 version 3 certificate structure}
    \label{fig:x509-certificate}
\end{figure}

In X.509, the certificate revocation process supports two possible mechanisms:

\begin{itemize}
	\item \textbf{Periodic Publication Mechanisms};
	\item \textbf{Online Query Mechanisms}.
\end{itemize}

In the \textbf{Periodic Publication Mechanism} the process consists of periodically issuing a \acl{CRL}. A \ac{CRL} is a timestamped list signed by the \ac{CA} or \ac{CRL} issuer that specifies the revoked certificates.

In Figure~\ref{fig:x509-crl} it is possible to view the several fields in the \ac{CRL} definition:

\begin{itemize}
	\item \textbf{tbsCertList}: contains the certificate list to be signed, which is represented by the following fields:
		\subitem \textbf{version}: \ac{CRL} version definition;
		\subitem \textbf{signature}: identifier of the cryptographic algorithm used to sign the \ac{CRL};
		\subitem \textbf{issuer}: describes the entity that signed and issued the CRL;
		\subitem \textbf{thisUpdate}: issue date of the \ac{CRL};
		\subitem \textbf{nextUpdate}: issue date of the next \ac{CRL}. A new \ac{CRL} must be issued before this date;
		\subitem \textbf{revokedCertificates}: the list of revoked certificates. Each revoked certificate is identified by its serial number in the \textit{userCertificate} field and should also specify the \textit{revocationDate} field;
		\subitem \textbf{crlExtensions}: optional field, meant to add additional attributes in the \ac{CRL};
	\item \textbf{signatureAlgorithm}: contains the identifier of the cryptographic algorithm used to sign the \textit{tbsCertList} content;
	\item \textbf{signatureValue}: contains a digital signature of the \textit{tbsCertList} content;
\end{itemize}

\begin{figure}[h!]
  \centering
	\begin{Verbatim}
		CertificateList  ::=  SEQUENCE  {
		  tbsCertList          TBSCertList,
		  signatureAlgorithm   AlgorithmIdentifier,
		  signatureValue       BIT STRING  }

		TBSCertList  ::=  SEQUENCE  {
		  version                 Version OPTIONAL,
		                          -- if present, MUST be v2
		  signature               AlgorithmIdentifier,
		  issuer                  Name,
		  thisUpdate              Time,
		  nextUpdate              Time OPTIONAL,
		  revokedCertificates     SEQUENCE OF SEQUENCE  {
		    userCertificate         CertificateSerialNumber,
		    revocationDate          Time,
		    crlEntryExtensions      Extensions OPTIONAL
		                          -- if present, version MUST be v2
		                            }  OPTIONAL,
		  crlExtensions           [0]  EXPLICIT Extensions OPTIONAL
		                          -- if present, version MUST be v2
                                                   }
	\end{Verbatim}
  \caption{X.509 v2 CRL structure}
\label{fig:x509-crl}
\end{figure}

In a \textit{periodic publication mechanism}, one of the key aspects is the
\textit{revocation delay}, that is the delay between the report of a revocation and the publishing of the updated \ac{CRL} in the repository.
This is an important  aspect, because there is the security risk of a user trusting an already revoked certificate.
This turns out to be a limitation, since the update scheduling of the \acp{CRL} may not be known.

In a \textbf{Online Query Mechanism}, the \textit{\ac{OCSP}}~\cite{rfc6960} is one of the main standards.
In the \ac{OCSP} system, the user sends a status request to a \ac{OCSP} \textit{responder}, that processes the request and replies to the sender with \textit{status information} about the queried certificate.
An \ac{OCSP} request contains the following fields:
\begin{itemize}
	\item protocol version;
	\item service request;
	\item target certificate identifier;
	\item optional extensions;
\end{itemize}
The \ac{OCSP} is a trusted entity.
Therefore, to ensure the authenticity of the response, the \ac{OCSP} responder digitally signs the response sent to the user.
The response contains the \textit{certificate identifier} and \textit{response validity interval}, besides the certificate status value.
In the certificate status field, the following indicators are possible:
\begin{itemize}
	\item \textit{good}: certificate has not been revoked, therefore is valid;
	\item \textit{revoked}: certificate has been revoked, temporarily or permanently;
	\item \textit{unknown}: information about the status of the certificate could not be obtained;
\end{itemize}

Even thought \ac{OCSP} tackles some of the shortcomings of a \textit{Periodic Publication Mechanism}, like \acp{CRL}, there are still some limitations.
The aforementioned \textit{revocation delay} may still exist while using \ac{OCSP}.
From the scalability side it can generate an huge overhead in the \ac{OCSP} Responder since clients ask for single certificates, even more in the case of high traffic services.
Also, \ac{OCSP} does not define how the necessary information is retrieved from the \ac{CRL} repository by the \ac{OCSP} responder.

The \ac{CA} model has some inherent problems~\cite{Schneier2000}:
\begin{itemize}
	\item The \ac{CA} needs to be a "trusted" entity, but delegating the certification tasks to a single entity without having knowledge of the system internals could be considered "blind trust". Having an open implementation system and the possibility of public audits could lessen this problem;
	\item As the \ac{CA} needs to identify the applicants before issuing the certificates, a proper mechanism to ensure the user true identity must be in-place.
\end{itemize}

\subsection{Web Of Trust}

In a \textit{Web of Trust}~\cite{Caronni2000} model, users trust a public key if it is obtained directly from the owner or a sufficient number of other trusted users recommend using the key.
This recommendation is done by vouching for someone's identity through the signing of their public keys.

\ac{PGP}~\cite{rfc4880} is a standard that implements the web of trust model.
The open-source implementation is \textit{GNU Privacy Guard}\footnote{https://www.gnupg.org/}.

Each \ac{PGP} user keeps a \textit{key ring}, where he stores his own public key and the public keys of other users.
Each key ring entry contains the following fields:
\begin{itemize}
	\item Public key of user;
	\item User identifier of the public key owner;
	\item Validity signatures of the public key and the respective user IDs of the signers;
	\item Owner trust;
	\item Key legitimacy, also known as key validity.
\end{itemize}

The \textit{owners trust} field is set by the key ring owner and indicates the level of trust the key ring owner has in the public key owner to sign other users' public keys.
It can take the values:

\begin{itemize}
	\item \textit{Ultimate}: assigned to key ring owners;
	\item \textit{Complete}: the key ring owner trusts totally the public key owner to sign other public keys;
	\item \textit{Marginal}: the key ring owner only trust marginally the public key owner to sing other public keys;
	\item \textit{None}: the key ring owner doens't trust the public key owner to sign other public keys;
	\item \textit{Unknown}: no information about the public key owner.
\end{itemize}

The \textit{key legitimacy} field indicates the trust of the key ring owner on the authenticity of the public key.
It is calculated by the number of signatures on the key and the owner-trust.
It can take the values:
\begin{itemize}
	\item \textit{Complete}: the owner is certain that the public key belongs to the user identifier depicted in the entry;
	\item \textit{Marginal}: the owner is marginally certain that the public key belongs to the user identifier depicted in the entry;
	\item \textit{None}: the owner is not sure that the public key belongs to the user identifier depicted in the entry.
\end{itemize}

In order to be able to use the OpenPGP standard, public keys and respective signatures must be exchanged.
This is possible by users exchanging directly their public keys or by using a \textit{key server}.
A key server is a public directory service that allows users to store and share public keys and their signatures.

\section{Blockchain and the Bitcoin protocol}
The blockchain is a distributed ledger and one of the key mechanisms behind the
Bitcoin~\cite{Nakamoto2008} cryptocurrency.
It allows a set of nodes to achieve consensus about the state of a dataset, by
leveraging a mechanism of proof of work.

At its core, a blockchain data structure consists of a linked list of blocks.
Each of these blocks contain several transaction records that occurred between any two bitcoin entities.
When a new transaction record is built, it is broadcast to all nodes in the network.
Each node groups a list of transactions into a block, tries to find a
proof-of-work for it and broadcasts the block to the network.
Then, each node verifies the proof-of-work, and if successful, adds the block to the blockchain.
This concept is called \textit{mining}, and every node that can attach a new block to the blockchain receives an incentive in the form of newly minted bitcoins.

\subsection{Block structure}

A block is a container data structure that aggregates transactions for inclusion in the blockchain~\cite{Antonopoulos2014}.

As seen in Figure~\ref{fig:blockchain-structure} a block has several required fields:

\begin{itemize}
  \item \textbf{Block Size}: size of the block, in bytes, minus this field;
  \item \textbf{Block Header}: contains several block related metadata;
  \item \textbf{Transaction Counter}: number of transactions in the block;
  \item \textbf{Transactions}: transactions contained in the block.
\end{itemize}
One of the most important fields in the block is the \textit{block header} field which contains the most important sets of metadata:

\begin{itemize}
  \item \textbf{Version}: software version number;
  \item \textbf{Previous Block Hash}: previous block reference;
  \item \textbf{Merkle Root}: root of the merkle tree that contains the block's transactions;
  \item \textbf{Timestamp}: creation time of this block (using Unix Epoch);
  \item \textbf{Difficulty Target}: difficulty of the proof-of-work algorithm for this block;
  \item \textbf{Nonce}: counter used by the proof-of-work algorithm.
\end{itemize}

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.5]{Figures/blockchain-structure.pdf}
  \caption{Blockchain structure and blocks content}
\label{fig:blockchain-structure}
\end{figure}

\subsection{Merkle Trees}
Each block stores a summary of all the transactions in the block in a multi-level data structure called \textit{Merkle Tree}.
In Figure~\ref{fig:merkle-tree} an merkle tree example is shown.

\textit{Merkle Trees} are binary trees containing cryptographic hashes built by hashing recursively the children nodes, using a bottom-top approach.
This allows summarizing the contents of large data sets and provides a secure and efficient form of verification of the data set integrity.

Checking if a data element is included in a tree with N hashed elements takes at most \(2*log_2(N)\) calculations.

\begin{figure}[htb]
  \centering
  \includegraphics[scale=0.5]{Figures/merkle-tree.pdf}
  \caption{Merkle tree example}
\label{fig:merkle-tree}
\end{figure}

This data structure is an essential component in the Bitcoin protocol, since it prevents tampering of the transactions by malicious users. In order to successfully swap in fake transactions into the bottom of the \textit{merkle tree}, it would be necessary to recalculate all the hashes of the nodes that are in the same sub-tree, up to the \textit{merkle root}. Given that each block may contain several hundreds of transactions, this could potentially be a very expensive operation, and by the time it is complete, already new blocks that point to previous real block could have been mined.

\subsection{Proof of work}
In Bitcoin, the proof-of-work involves scanning for a value that when hashed together with block, the hash begins with a number of zero bits. This is calculated by incrementing a nonce in the block until a value is found that gives the block's hash the required number of zero bits.

Using this proof-of-work system, the problem of majority decision making is solved since this is a one-CPU-one-vote voting system.

\subsection{Blockchain applications}
Some systems were built on top of the blockchain by forking the Bitcoin project.
\textit{Namecoin}\footnote{https://namecoin.info/} is one of them, and is a decentralized name and information register. It can be used as a decentralized DNS or to save identity information like GPG keys, email information, etc.

\subsection{Smart Contracts} The concept of Smart Contracts\footnote{"The Idea of Smart Contracts" - http://szabo.best.vwh.net/idea.html}~\cite{40673} is the one of contracts: allowing to establish an agreement between several mutually suspicious parties. But smart contracts have the specificity of being possible to describe via program code and therefore, it is possible to enforce them programmatically and automatically.
The Bitcoin protocol has a scripting system that is used for transactions and can be used to build a limited implementation of smart contracts.


\subsection{Blockchain implementations}

There are a number of different blockchain implementations currently available that enable developers to build applications on top of it using smart contracts, like Ethereum\footnote{https://github.com/ethereum/wiki/wiki/White-Paper}, Hyperledger Fabric~\cite{cachin2016architecture} or R3 Corda~\cite{mikehearn2016} – with the last two implementations having more specific use-cases: enterprise and finances, respectively.

A quick analysis between these three platforms shows significant architectural differences, in such a way that we can even consider an higher-level classification for these three platforms, since not all of them show the main characteristics of a blockchain (taking in consideration the Bitcoin reference paper).
A broader definition that encapsulates these three platforms is \ac{DLT}.

The Hyperledger Fabric platform has a modular approach to blockchains. It's a private blockchain system  and is permissioned, i.e doesn't allow unknown entities to participate in the system.
To participate in the system the members of a Hyperledger Fabric system, must enroll through a \ac{MSP}.
This allows different architectural approaches in the system, because it is not strictly necessary to have a \ac{POW} mechanism, like in Ethereum or Bitcoin (which may be considered open networks), and it is possible to use different consensus mechanisms in the network.
Also, there isn't any built-in currency like in Bitcoin or Ethereum.

The R3 Corda system is considered a \ac{DLT} for financial institutions.
It is also permissioned and private and uses a concept of notary nodes to validate uniqueness of transactions. Like Fabric, it also allows a more fine-grained control of the consensus mechanism.
Data is shared on a need-to-know basis, there is no global broadcast of all the transactions in the system.

Finally, the Ethereum platform is the more generic blockchain platform of the ones referenced.
It is permission-less, and can be public or private.
All the participants have to achieve consensus over all the transactions of the system, using the \ac{POW} consensus and leveraging the built-in currency (ether).

\subsection{Ethereum} Ethereum is a protocol for building distributed applications on top of a blockchain, with a Turing-complete programming language, using the smart contract concept.
It uses an internal cryptocurrency, \textit{ether} which is similar to bitcoin, and is used to reward the computational resources used to process the smart contracts and securing the network.

In Ethereum there are two types of accounts:

\begin{itemize}
	\item \textbf{externally owned accounts} are controlled by users in possession of a private key, and are able to send messages through transactions;
	\item \textbf{contract accounts} are controlled by \textit{contract code}, which is executed every time it receives a message.
\end{itemize}

Each share a similar data structure, which contain the following fields:
\begin{itemize}
	\item \textbf{Nounce};
	\item \textbf{Current ether balance};
	\item \textbf{Contract code} (if it is a contract account);
	\item \textbf{Storage};
\end{itemize}

The communication model in Ethereum works through the concept of \textbf{messages} and \textbf{transactions}.

In Ethereum, a transaction is a signed data package that contains the message that a \textit{externally owned account} wants to send. It contains the following fields:

\begin{itemize}
	\item \textbf{Message recipient};
	\item \textbf{Sender signature};
	\item \textbf{Ether amount} to transfer;
	\item \textbf{Data field} (optional), that can be used to send user-defined data to the contract;
	\item \textbf{STARTGAS value}, value that represent the maximum computational steps the transaction can take;
	\item \textbf{GASPRICE value}, the fee payed by the sender per computational step.
\end{itemize}

Ethereum prevents denial of service attacks that target resource consumption by using a unit to represent computational steps, called "gas".
Each computational step that a user wants to execute requires the payment of a gas fee.
This way, an attacker that tries to consume extra computational resources or create contract loops, will pay a gas fee proportional to the consumed resources.

\textit{Messages} in Ethereum are virtual objects that can be exchanged between contract accounts, and only exist in the \ac{EVM}.

\begin{itemize}
	\item \textbf{Message sender};
	\item \textbf{Message recipient};
	\item \textbf{Ether amount} to transfer;
	\item \textbf{Data field} (optional);
	\item \textbf{STARTGAS} value.
\end{itemize}

The propose of messages is to create a relationship between contracts, so it is possible for contracts to trigger the execution of other contracts.
An important detail is that the assigned gas to the execution of the contract,
must also take into account the gas consumed by execution of the other contracts required by the top contract.

\subsubsection{Contract code} The contract code is written in a stack-based bytecode language called \textit{\ac{EVM} code}.
The code execution is done in an infinite loop that repeatedly runs the operation in the current program counter position, until the end of the code, an error or return statement is reached.

The contracts code could be written in Solidity\footnote{http://ethereum.github.io/solidity/} a high-level contract language that can be compiled to \ac{EVM} code.
In Figure~\ref{fig:solidity-example} an simple Solidity contract is shown.
This contract defines two functions that allows anyone to save a value to the contract internal storage and retrieve it after.

\begin{figure}[h!]
  \centering
                    \begin{Verbatim}
                      contract DataStorage {
                        uint dataStore;

                        function set(uint a) {
                          dataStore = a;
                        }

                        function get() constant returns (uint val) {
                          return dataStore;
                        }
                      }
                    \end{Verbatim}
  \caption{Simple data storage contract in Solidity language}
\label{fig:solidity-example}
\end{figure}

The Ethereum protocol, therefore allows to build several secure distributed applications by applying the abstract smart contract model: voting systems, decentralized file storage, \ac{DAO}, identity and reputation systems, etc

\section{Chapter Summary}

In the previous sections we described the internals of \ac{P2P} systems, more precisely \ac{DHT} systems.

We focused on the security considerations of \acp{DHT} by analyzing the possible attacks: routing attacks, storage and retrieval attacks, Sybil Attack and Eclipse Attack.

We analyzed in greater detail the available mechanisms of defense against Sybil attacks, based on centralized certification, network characteristics, computational puzzles, social networks or game theory.
Of all of those mechanisms, only centralized certificate is able to completely eliminate Sybil attacks.

We then analyzed \ac{PKI} infrastructures and blockchain systems as potential complementary mechanisms that we could potentially use in our solution.

